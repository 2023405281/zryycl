import tensorflow as tf
from tensorflow.keras.models import load_model
import numpy as np
import os
import json

# å…¨å±€é…ç½®ï¼ˆå¯æ ¹æ®ä½ çš„æ¨¡å‹å®é™…æƒ…å†µè°ƒæ•´ï¼‰
MODEL_CONFIG = {
    # æ–‡æœ¬é¢„å¤„ç†é…ç½®ï¼ˆéœ€ä¸æ¨¡å‹è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    "MAX_SEQ_LEN": 128,          # æ–‡æœ¬æœ€å¤§é•¿åº¦
    "VOCAB_SIZE": 10000,         # è¯æ±‡è¡¨å¤§å°
    "EMBEDDING_DIM": 128,        # åµŒå…¥å±‚ç»´åº¦
    # ä»»åŠ¡ç›¸å…³é…ç½®
    "CLASSIFY_LABELS": ["ç§‘æŠ€", "æ•™è‚²", "å¨±ä¹", "è´¢ç»", "ä½“è‚²"],  # æ–‡æœ¬åˆ†ç±»æ ‡ç­¾
    "SENTIMENT_LABELS": ["è´Ÿé¢", "ä¸­æ€§", "æ­£é¢"],                # æƒ…æ„Ÿåˆ†ææ ‡ç­¾
    "TRANSLATE_MAX_LEN": 64,     # ç¿»è¯‘æ–‡æœ¬æœ€å¤§é•¿åº¦
    # é»˜è®¤å¡«å……/æœªçŸ¥token
    "PAD_TOKEN": 0,
    "UNK_TOKEN": 1
}

def load_nlp_model(model_path: str) -> dict:
    """
    åŠ è½½è®­ç»ƒå¥½çš„.h5æ ¼å¼NLPæ¨¡å‹
    :param model_path: .h5æ¨¡å‹æ–‡ä»¶è·¯å¾„
    :return: åŒ…å«æ¨¡å‹å®ä¾‹å’Œé…ç½®çš„å­—å…¸ï¼ŒåŠ è½½å¤±è´¥è¿”å›None
    """
    try:
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{model_path}")
            return None
        
        # ç¦ç”¨TensorFlowä¸å¿…è¦çš„æ—¥å¿—
        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
        tf.get_logger().setLevel('ERROR')
        
        # åŠ è½½.h5æ¨¡å‹ï¼ˆå…¼å®¹è‡ªå®šä¹‰å±‚/å‡½æ•°ï¼‰
        model = load_model(
            model_path,
            compile=False,  # æ¨ç†é˜¶æ®µæ— éœ€ç¼–è¯‘
            custom_objects=None  # è‹¥æœ‰è‡ªå®šä¹‰å±‚ï¼Œéœ€åœ¨æ­¤æŒ‡å®š
        )
        
        print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹ï¼š{model_path}")
        print(f"ğŸ“Œ æ¨¡å‹è¾“å…¥å½¢çŠ¶ï¼š{model.input_shape}")
        print(f"ğŸ“Œ æ¨¡å‹è¾“å‡ºå½¢çŠ¶ï¼š{model.output_shape}")
        
        # è¿”å›æ¨¡å‹å®ä¾‹å’Œé…ç½®
        return {
            "model": model,
            "config": MODEL_CONFIG,
            "status": "loaded"
        }
    
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥ï¼š{str(e)}")
        return None

def preprocess_input(text: str, config: dict) -> np.ndarray:
    """
    æ–‡æœ¬é¢„å¤„ç†ï¼ˆå¯¹æ¥utils.data_utilsï¼‰
    :param text: åŸå§‹è¾“å…¥æ–‡æœ¬
    :param config: æ¨¡å‹é…ç½®å­—å…¸
    :return: æ¨¡å‹å¯æ¥å—çš„å¼ é‡è¾“å…¥ï¼ˆshape: (1, MAX_SEQ_LEN)ï¼‰
    """
    try:
        from utils.data_utils import preprocess_text
        return preprocess_text(text, config)
    except Exception as e:
        print(f"âŒ è°ƒç”¨utilsé¢„å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨é€»è¾‘ï¼š{str(e)}")
        # å¤‡ç”¨é€»è¾‘ï¼ˆå…¼å®¹æ— utilsçš„æƒ…å†µï¼‰
        text = text[:config["MAX_SEQ_LEN"]]
        char_ids = [ord(c) % config["VOCAB_SIZE"] for c in text]
        char_ids += [config["PAD_TOKEN"]] * (config["MAX_SEQ_LEN"] - len(char_ids))
        return np.array([char_ids[:config["MAX_SEQ_LEN"]]], dtype=np.int32)

def infer_nlp_model(model_wrapper: dict, text: str, task_type: str) -> str:
    """
    è°ƒç”¨æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œé€‚é…ä¸åŒä»»åŠ¡ç±»å‹
    :param model_wrapper: load_nlp_modelè¿”å›çš„æ¨¡å‹åŒ…è£…å­—å…¸
    :param text: è¾“å…¥æ–‡æœ¬
    :param task_type: ä»»åŠ¡ç±»å‹ï¼ˆclassify/sentiment/translateï¼‰
    :return: äººç±»å¯è¯»çš„æ¨ç†ç»“æœå­—ç¬¦ä¸²
    """
    # æ ¡éªŒè¾“å…¥
    if not model_wrapper or model_wrapper["status"] != "loaded":
        return "æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œæ¨ç†"
    if not text:
        return "è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º"
    if task_type not in ["classify", "sentiment", "translate"]:
        return f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹ï¼š{task_type}ï¼Œä»…æ”¯æŒclassify/sentiment/translate"
    
    try:
        # 1. æ–‡æœ¬é¢„å¤„ç†
        input_tensor = preprocess_input(text, model_wrapper["config"])
        if input_tensor is None:
            return "æ–‡æœ¬é¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•æ¨ç†"
        
        # 2. æ¨¡å‹æ¨ç†
        model = model_wrapper["model"]
        predictions = model.predict(input_tensor, verbose=0)
        
        # 3. æ ¹æ®ä»»åŠ¡ç±»å‹è§£æé¢„æµ‹ç»“æœ
        if task_type == "classify":
            # æ–‡æœ¬åˆ†ç±»ï¼šå–æ¦‚ç‡æœ€å¤§çš„æ ‡ç­¾
            pred_idx = np.argmax(predictions[0])
            pred_label = model_wrapper["config"]["CLASSIFY_LABELS"][pred_idx]
            pred_prob = round(float(np.max(predictions[0])), 4)
            return f"åˆ†ç±»ç»“æœï¼š{pred_label}ï¼ˆç½®ä¿¡åº¦ï¼š{pred_prob}ï¼‰\næ‰€æœ‰ç±»åˆ«æ¦‚ç‡ï¼š{dict(zip(model_wrapper['config']['CLASSIFY_LABELS'], predictions[0].round(4)))}"
        
        elif task_type == "sentiment":
            # æƒ…æ„Ÿåˆ†æï¼šå–æ¦‚ç‡æœ€å¤§çš„æ ‡ç­¾
            pred_idx = np.argmax(predictions[0])
            pred_label = model_wrapper["config"]["SENTIMENT_LABELS"][pred_idx]
            pred_prob = round(float(np.max(predictions[0])), 4)
            return f"æƒ…æ„Ÿåˆ†æç»“æœï¼š{pred_label}ï¼ˆç½®ä¿¡åº¦ï¼š{pred_prob}ï¼‰\nè´Ÿé¢æ¦‚ç‡ï¼š{predictions[0][0].round(4)} | ä¸­æ€§æ¦‚ç‡ï¼š{predictions[0][1].round(4)} | æ­£é¢æ¦‚ç‡ï¼š{predictions[0][2].round(4)}"
        
        elif task_type == "translate":
            # æœºå™¨ç¿»è¯‘ï¼šç¤ºä¾‹é€»è¾‘ï¼ˆéœ€æ ¹æ®ä½ çš„æ¨¡å‹è¾“å‡ºè°ƒæ•´ï¼‰
            # æ­¤å¤„ä»…ä¸ºå ä½ï¼Œéœ€æ›¿æ¢ä¸ºå®é™…çš„ç¿»è¯‘IDè½¬æ–‡æœ¬é€»è¾‘
            pred_ids = predictions[0].argmax(axis=-1)[:model_wrapper["config"]["TRANSLATE_MAX_LEN"]]
            # ç¤ºä¾‹ï¼šIDè½¬å›å­—ç¬¦ï¼ˆå®é™…éœ€åŠ è½½ç¿»è¯‘è¯æ±‡è¡¨ï¼‰
            translate_text = "".join([chr(int(id) % 65535) for id in pred_ids if id != model_wrapper["config"]["PAD_TOKEN"]])
            return f"ç¿»è¯‘ç»“æœï¼š{translate_text.strip()}"
    
    except Exception as e:
        return f"æ¨ç†å¤±è´¥ï¼š{str(e)}"

# æµ‹è¯•ä»£ç ï¼ˆå•ç‹¬è¿è¡Œè¯¥æ–‡ä»¶éªŒè¯æ¨¡å‹åŠ è½½å’Œæ¨ç†ï¼‰
if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    TEST_MODEL_PATH = "../model/nlp_multi_task.h5"  # æ¨¡å‹è·¯å¾„
    model_wrapper = load_nlp_model(TEST_MODEL_PATH)
    
    if model_wrapper:
        # æµ‹è¯•ä¸åŒä»»åŠ¡çš„æ¨ç†
        TEST_TEXT = "äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•ç»™æ•™è‚²è¡Œä¸šå¸¦æ¥äº†å·¨å¤§å˜é©"
        
        print("\n===== æ–‡æœ¬åˆ†ç±»æµ‹è¯• =====")
        classify_result = infer_nlp_model(model_wrapper, TEST_TEXT, "classify")
        print(classify_result)
        
        print("\n===== æƒ…æ„Ÿåˆ†ææµ‹è¯• =====")
        sentiment_result = infer_nlp_model(model_wrapper, TEST_TEXT, "sentiment")
        print(sentiment_result)
        
        print("\n===== æœºå™¨ç¿»è¯‘æµ‹è¯• =====")
        translate_result = infer_nlp_model(model_wrapper, TEST_TEXT, "translate")
        print(translate_result)